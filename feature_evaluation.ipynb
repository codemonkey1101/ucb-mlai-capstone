{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd86ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7450f7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder, LabelEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectFromModel, RFECV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "965a1d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 320 entries, (2022, 'Seattle Seahawks') to (2021, 'Seattle Seahawks')\n",
      "Data columns (total 67 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   MadePlayoffs                     320 non-null    float64\n",
      " 1   QB_COST                          320 non-null    int64  \n",
      " 2   RB_COST                          320 non-null    int64  \n",
      " 3   WR_COST                          320 non-null    int64  \n",
      " 4   TE_COST                          320 non-null    int64  \n",
      " 5   OL_COST                          320 non-null    int64  \n",
      " 6   Offense_COST                     320 non-null    int64  \n",
      " 7   IDL_COST                         320 non-null    int64  \n",
      " 8   EDGE_COST                        320 non-null    int64  \n",
      " 9   LB_COST                          320 non-null    int64  \n",
      " 10  S_COST                           320 non-null    int64  \n",
      " 11  CB_COST                          320 non-null    int64  \n",
      " 12  Defense_COST                     320 non-null    int64  \n",
      " 13  offense_completion_percentage    320 non-null    float64\n",
      " 14  offense_total_yards_gained_pass  320 non-null    int64  \n",
      " 15  offense_total_yards_gained_run   320 non-null    int64  \n",
      " 16  offense_ave_yards_gained_pass    320 non-null    float64\n",
      " 17  offense_ave_yards_gained_run     320 non-null    float64\n",
      " 18  offense_total_air_yards          320 non-null    int64  \n",
      " 19  offense_ave_air_yards            320 non-null    float64\n",
      " 20  offense_total_yac                320 non-null    int64  \n",
      " 21  offense_ave_yac                  320 non-null    float64\n",
      " 22  offense_n_plays_pass             320 non-null    int64  \n",
      " 23  offense_n_plays_run              320 non-null    int64  \n",
      " 24  offense_n_interceptions          320 non-null    int64  \n",
      " 25  offense_n_fumbles_lost_pass      320 non-null    int64  \n",
      " 26  offense_n_fumbles_lost_run       320 non-null    int64  \n",
      " 27  offense_total_epa_pass           320 non-null    float64\n",
      " 28  offense_total_epa_run            320 non-null    float64\n",
      " 29  offense_ave_epa_pass             320 non-null    float64\n",
      " 30  offense_ave_epa_run              320 non-null    float64\n",
      " 31  offense_total_wpa_pass           320 non-null    float64\n",
      " 32  offense_total_wpa_run            320 non-null    float64\n",
      " 33  offense_ave_wpa_pass             320 non-null    float64\n",
      " 34  offense_ave_wpa_run              320 non-null    float64\n",
      " 35  offense_success_rate_pass        320 non-null    float64\n",
      " 36  offense_success_rate_run         320 non-null    float64\n",
      " 37  defense_completion_percentage    320 non-null    float64\n",
      " 38  defense_total_yards_gained_pass  320 non-null    int64  \n",
      " 39  defense_total_yards_gained_run   320 non-null    int64  \n",
      " 40  defense_ave_yards_gained_pass    320 non-null    float64\n",
      " 41  defense_ave_yards_gained_run     320 non-null    float64\n",
      " 42  defense_total_air_yards          320 non-null    int64  \n",
      " 43  defense_ave_air_yards            320 non-null    float64\n",
      " 44  defense_total_yac                320 non-null    int64  \n",
      " 45  defense_ave_yac                  320 non-null    float64\n",
      " 46  defense_n_plays_pass             320 non-null    int64  \n",
      " 47  defense_n_plays_run              320 non-null    int64  \n",
      " 48  defense_n_interceptions          320 non-null    int64  \n",
      " 49  defense_n_fumbles_lost_pass      320 non-null    int64  \n",
      " 50  defense_n_fumbles_lost_run       320 non-null    int64  \n",
      " 51  defense_total_epa_pass           320 non-null    float64\n",
      " 52  defense_total_epa_run            320 non-null    float64\n",
      " 53  defense_ave_epa_pass             320 non-null    float64\n",
      " 54  defense_ave_epa_run              320 non-null    float64\n",
      " 55  defense_total_wpa_pass           320 non-null    float64\n",
      " 56  defense_total_wpa_run            320 non-null    float64\n",
      " 57  defense_ave_wpa_pass             320 non-null    float64\n",
      " 58  defense_ave_wpa_run              320 non-null    float64\n",
      " 59  defense_success_rate_pass        320 non-null    float64\n",
      " 60  defense_success_rate_run         320 non-null    float64\n",
      " 61  points_scored                    320 non-null    int64  \n",
      " 62  points_allowed                   320 non-null    int64  \n",
      " 63  wins                             320 non-null    int64  \n",
      " 64  losses                           320 non-null    int64  \n",
      " 65  ties                             320 non-null    int64  \n",
      " 66  score_differential               320 non-null    int64  \n",
      "dtypes: float64(31), int64(36)\n",
      "memory usage: 169.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('intermediate-data/nfl_team_all_stats_2013_2022.csv', index_col=['Year', 'Team'])\n",
    "df.drop(df.columns[df.columns.str.contains('unnamed', case=False)], axis=1, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5e24bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MadePlayoffs</th>\n",
       "      <th>QB_COST</th>\n",
       "      <th>RB_COST</th>\n",
       "      <th>WR_COST</th>\n",
       "      <th>TE_COST</th>\n",
       "      <th>OL_COST</th>\n",
       "      <th>Offense_COST</th>\n",
       "      <th>IDL_COST</th>\n",
       "      <th>EDGE_COST</th>\n",
       "      <th>LB_COST</th>\n",
       "      <th>...</th>\n",
       "      <th>defense_ave_wpa_pass</th>\n",
       "      <th>defense_ave_wpa_run</th>\n",
       "      <th>defense_success_rate_pass</th>\n",
       "      <th>defense_success_rate_run</th>\n",
       "      <th>points_scored</th>\n",
       "      <th>points_allowed</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>ties</th>\n",
       "      <th>score_differential</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th>Team</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2022</th>\n",
       "      <th>Seattle Seahawks</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1557085</td>\n",
       "      <td>10799653</td>\n",
       "      <td>16831423</td>\n",
       "      <td>12778788</td>\n",
       "      <td>27955261</td>\n",
       "      <td>69922210</td>\n",
       "      <td>7701509</td>\n",
       "      <td>25013832</td>\n",
       "      <td>7377232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>0.424958</td>\n",
       "      <td>0.410609</td>\n",
       "      <td>407</td>\n",
       "      <td>401</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Francisco 49ers</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2897535</td>\n",
       "      <td>9284062</td>\n",
       "      <td>16963177</td>\n",
       "      <td>10569598</td>\n",
       "      <td>17581156</td>\n",
       "      <td>57295528</td>\n",
       "      <td>11028483</td>\n",
       "      <td>10194288</td>\n",
       "      <td>7666512</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001752</td>\n",
       "      <td>-0.002444</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>450</td>\n",
       "      <td>277</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona Cardinals</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6172993</td>\n",
       "      <td>5306754</td>\n",
       "      <td>15022466</td>\n",
       "      <td>4425078</td>\n",
       "      <td>19171690</td>\n",
       "      <td>50098981</td>\n",
       "      <td>20498000</td>\n",
       "      <td>5347625</td>\n",
       "      <td>7964030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.508716</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>340</td>\n",
       "      <td>449</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>-109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Los Angeles Rams</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13705176</td>\n",
       "      <td>2637944</td>\n",
       "      <td>5479738</td>\n",
       "      <td>6217555</td>\n",
       "      <td>19240160</td>\n",
       "      <td>47280573</td>\n",
       "      <td>9376091</td>\n",
       "      <td>13967275</td>\n",
       "      <td>15711252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003280</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.477234</td>\n",
       "      <td>0.415730</td>\n",
       "      <td>307</td>\n",
       "      <td>384</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carolina Panthers</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7579454</td>\n",
       "      <td>9290450</td>\n",
       "      <td>11041036</td>\n",
       "      <td>4325000</td>\n",
       "      <td>18981126</td>\n",
       "      <td>51217066</td>\n",
       "      <td>5096152</td>\n",
       "      <td>11629844</td>\n",
       "      <td>12335911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>-0.000132</td>\n",
       "      <td>0.455285</td>\n",
       "      <td>0.425263</td>\n",
       "      <td>347</td>\n",
       "      <td>374</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          MadePlayoffs   QB_COST   RB_COST   WR_COST  \\\n",
       "Year Team                                                              \n",
       "2022 Seattle Seahawks              1.0   1557085  10799653  16831423   \n",
       "     San Francisco 49ers           1.0   2897535   9284062  16963177   \n",
       "     Arizona Cardinals             0.0   6172993   5306754  15022466   \n",
       "     Los Angeles Rams              0.0  13705176   2637944   5479738   \n",
       "     Carolina Panthers             0.0   7579454   9290450  11041036   \n",
       "\n",
       "                           TE_COST   OL_COST  Offense_COST  IDL_COST  \\\n",
       "Year Team                                                              \n",
       "2022 Seattle Seahawks     12778788  27955261      69922210   7701509   \n",
       "     San Francisco 49ers  10569598  17581156      57295528  11028483   \n",
       "     Arizona Cardinals     4425078  19171690      50098981  20498000   \n",
       "     Los Angeles Rams      6217555  19240160      47280573   9376091   \n",
       "     Carolina Panthers     4325000  18981126      51217066   5096152   \n",
       "\n",
       "                          EDGE_COST   LB_COST  ...  defense_ave_wpa_pass  \\\n",
       "Year Team                                      ...                         \n",
       "2022 Seattle Seahawks      25013832   7377232  ...              0.002187   \n",
       "     San Francisco 49ers   10194288   7666512  ...             -0.001752   \n",
       "     Arizona Cardinals      5347625   7964030  ...              0.001529   \n",
       "     Los Angeles Rams      13967275  15711252  ...              0.003280   \n",
       "     Carolina Panthers     11629844  12335911  ...              0.001560   \n",
       "\n",
       "                          defense_ave_wpa_run  defense_success_rate_pass  \\\n",
       "Year Team                                                                  \n",
       "2022 Seattle Seahawks                0.002329                   0.424958   \n",
       "     San Francisco 49ers            -0.002444                   0.422535   \n",
       "     Arizona Cardinals               0.002561                   0.508716   \n",
       "     Los Angeles Rams                0.002446                   0.477234   \n",
       "     Carolina Panthers              -0.000132                   0.455285   \n",
       "\n",
       "                          defense_success_rate_run  points_scored  \\\n",
       "Year Team                                                           \n",
       "2022 Seattle Seahawks                     0.410609            407   \n",
       "     San Francisco 49ers                  0.370370            450   \n",
       "     Arizona Cardinals                    0.435897            340   \n",
       "     Los Angeles Rams                     0.415730            307   \n",
       "     Carolina Panthers                    0.425263            347   \n",
       "\n",
       "                          points_allowed  wins  losses  ties  \\\n",
       "Year Team                                                      \n",
       "2022 Seattle Seahawks                401     9       8     0   \n",
       "     San Francisco 49ers             277    13       4     0   \n",
       "     Arizona Cardinals               449     4      13     0   \n",
       "     Los Angeles Rams                384     5      12     0   \n",
       "     Carolina Panthers               374     7      10     0   \n",
       "\n",
       "                          score_differential  \n",
       "Year Team                                     \n",
       "2022 Seattle Seahawks                      6  \n",
       "     San Francisco 49ers                 173  \n",
       "     Arizona Cardinals                  -109  \n",
       "     Los Angeles Rams                    -77  \n",
       "     Carolina Panthers                   -27  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2f6d974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MadePlayoffs\n",
       "0.0    194\n",
       "1.0    126\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset balance of subscribed class (derived from column '1 or 0').\n",
    "df['MadePlayoffs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "adf5c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get column names for target categories, off-stats, def-stats, off-cost, def-cost\n",
    "target_categorical_columns = ['points_scored', 'points_allowed', 'score_differential', 'MadePlayoffs', 'wins', 'losses', 'ties']\n",
    "off_cost_columns =  ['QB_COST', 'RB_COST', 'WR_COST', 'TE_COST', 'OL_COST', 'Offense_COST']\n",
    "def_cost_columns = ['IDL_COST', 'EDGE_COST', 'LB_COST', 'S_COST', 'CB_COST', 'Defense_COST']\n",
    "off_stats_columns = ['offense_completion_percentage', 'offense_total_yards_gained_pass', 'offense_total_yards_gained_run', 'offense_ave_yards_gained_pass', 'offense_ave_yards_gained_run', 'offense_total_air_yards', 'offense_ave_air_yards', 'offense_total_yac', 'offense_ave_yac', 'offense_n_plays_pass', 'offense_n_plays_run', 'offense_n_interceptions', 'offense_n_fumbles_lost_pass', 'offense_n_fumbles_lost_run', 'offense_total_epa_pass', 'offense_total_epa_run', 'offense_ave_epa_pass', 'offense_ave_epa_run', 'offense_total_wpa_pass', 'offense_total_wpa_run', 'offense_ave_wpa_pass', 'offense_ave_wpa_run', 'offense_success_rate_pass', 'offense_success_rate_run']\n",
    "def_stats_columns = ['defense_completion_percentage', 'defense_total_yards_gained_pass', 'defense_total_yards_gained_run', 'defense_ave_yards_gained_pass', 'defense_ave_yards_gained_run', 'defense_total_air_yards', 'defense_ave_air_yards', 'defense_total_yac', 'defense_ave_yac', 'defense_n_plays_pass', 'defense_n_plays_run', 'defense_n_interceptions', 'defense_n_fumbles_lost_pass', 'defense_n_fumbles_lost_run', 'defense_total_epa_pass', 'defense_total_epa_run', 'defense_ave_epa_pass', 'defense_ave_epa_run', 'defense_total_wpa_pass', 'defense_total_wpa_run', 'defense_ave_wpa_pass', 'defense_ave_wpa_run', 'defense_success_rate_pass', 'defense_success_rate_run']\n",
    "\n",
    "numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "feature_columns = df.drop(['points_scored', 'points_allowed', 'score_differential', 'MadePlayoffs', 'wins', 'losses', 'ties'], axis=1).columns.tolist()\n",
    "\n",
    "# create training and test data frames where the training data is from the year prior to 2021 and\n",
    "# test data is after 2020.\n",
    "\n",
    "# target categories\n",
    "y_lte_2020 = df.loc[:, ['MadePlayoffs']].query('Year <= 2020').MadePlayoffs.reset_index(drop=True) # training data\n",
    "y_gt_2020 = df.loc[:, ['MadePlayoffs']].query('Year > 2020').MadePlayoffs.reset_index(drop=True) #test data\n",
    "\n",
    "# feature data\n",
    "target_list = off_stats_columns + def_stats_columns + list(['points_scored', 'points_allowed', 'score_differential', 'wins', 'losses', 'ties'])\n",
    "X_lte_2020 = df.loc[:, target_list].query('Year <= 2020').reset_index(drop=True) # training data\n",
    "X_gt_2020 = df.loc[:, target_list].query('Year > 2020').reset_index(drop=True) # test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9214ffff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offense_completion_percentage</th>\n",
       "      <th>offense_total_yards_gained_pass</th>\n",
       "      <th>offense_total_yards_gained_run</th>\n",
       "      <th>offense_ave_yards_gained_pass</th>\n",
       "      <th>offense_ave_yards_gained_run</th>\n",
       "      <th>offense_total_air_yards</th>\n",
       "      <th>offense_ave_air_yards</th>\n",
       "      <th>offense_total_yac</th>\n",
       "      <th>offense_ave_yac</th>\n",
       "      <th>offense_n_plays_pass</th>\n",
       "      <th>...</th>\n",
       "      <th>defense_ave_wpa_pass</th>\n",
       "      <th>defense_ave_wpa_run</th>\n",
       "      <th>defense_success_rate_pass</th>\n",
       "      <th>defense_success_rate_run</th>\n",
       "      <th>points_scored</th>\n",
       "      <th>points_allowed</th>\n",
       "      <th>score_differential</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>ties</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.570571</td>\n",
       "      <td>4091</td>\n",
       "      <td>2084</td>\n",
       "      <td>6.142643</td>\n",
       "      <td>4.590308</td>\n",
       "      <td>5288</td>\n",
       "      <td>8.474359</td>\n",
       "      <td>2014</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>666</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000379</td>\n",
       "      <td>-0.000629</td>\n",
       "      <td>0.430818</td>\n",
       "      <td>0.416842</td>\n",
       "      <td>444</td>\n",
       "      <td>338</td>\n",
       "      <td>106</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.505703</td>\n",
       "      <td>2932</td>\n",
       "      <td>2164</td>\n",
       "      <td>5.574144</td>\n",
       "      <td>4.461856</td>\n",
       "      <td>4326</td>\n",
       "      <td>9.031315</td>\n",
       "      <td>1345</td>\n",
       "      <td>5.056391</td>\n",
       "      <td>526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>-0.003379</td>\n",
       "      <td>0.433600</td>\n",
       "      <td>0.297561</td>\n",
       "      <td>290</td>\n",
       "      <td>387</td>\n",
       "      <td>-97</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.550077</td>\n",
       "      <td>3567</td>\n",
       "      <td>1447</td>\n",
       "      <td>5.496148</td>\n",
       "      <td>4.255882</td>\n",
       "      <td>5690</td>\n",
       "      <td>9.660441</td>\n",
       "      <td>1535</td>\n",
       "      <td>4.299720</td>\n",
       "      <td>649</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.434572</td>\n",
       "      <td>0.445161</td>\n",
       "      <td>317</td>\n",
       "      <td>335</td>\n",
       "      <td>-18</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.523643</td>\n",
       "      <td>3107</td>\n",
       "      <td>2338</td>\n",
       "      <td>5.441331</td>\n",
       "      <td>4.428030</td>\n",
       "      <td>4506</td>\n",
       "      <td>8.648752</td>\n",
       "      <td>1508</td>\n",
       "      <td>5.043478</td>\n",
       "      <td>571</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003505</td>\n",
       "      <td>-0.000593</td>\n",
       "      <td>0.378029</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>339</td>\n",
       "      <td>388</td>\n",
       "      <td>-49</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.590909</td>\n",
       "      <td>4136</td>\n",
       "      <td>1770</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>3.839479</td>\n",
       "      <td>5023</td>\n",
       "      <td>8.571672</td>\n",
       "      <td>2080</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>616</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002240</td>\n",
       "      <td>-0.003505</td>\n",
       "      <td>0.422018</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>430</td>\n",
       "      <td>305</td>\n",
       "      <td>125</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   offense_completion_percentage  offense_total_yards_gained_pass  \\\n",
       "0                       0.570571                             4091   \n",
       "1                       0.505703                             2932   \n",
       "2                       0.550077                             3567   \n",
       "3                       0.523643                             3107   \n",
       "4                       0.590909                             4136   \n",
       "\n",
       "   offense_total_yards_gained_run  offense_ave_yards_gained_pass  \\\n",
       "0                            2084                       6.142643   \n",
       "1                            2164                       5.574144   \n",
       "2                            1447                       5.496148   \n",
       "3                            2338                       5.441331   \n",
       "4                            1770                       6.714286   \n",
       "\n",
       "   offense_ave_yards_gained_run  offense_total_air_yards  \\\n",
       "0                      4.590308                     5288   \n",
       "1                      4.461856                     4326   \n",
       "2                      4.255882                     5690   \n",
       "3                      4.428030                     4506   \n",
       "4                      3.839479                     5023   \n",
       "\n",
       "   offense_ave_air_yards  offense_total_yac  offense_ave_yac  \\\n",
       "0               8.474359               2014         5.300000   \n",
       "1               9.031315               1345         5.056391   \n",
       "2               9.660441               1535         4.299720   \n",
       "3               8.648752               1508         5.043478   \n",
       "4               8.571672               2080         5.714286   \n",
       "\n",
       "   offense_n_plays_pass  ...  defense_ave_wpa_pass  defense_ave_wpa_run  \\\n",
       "0                   666  ...             -0.000379            -0.000629   \n",
       "1                   526  ...              0.000320            -0.003379   \n",
       "2                   649  ...             -0.002415             0.001803   \n",
       "3                   571  ...             -0.003505            -0.000593   \n",
       "4                   616  ...             -0.002240            -0.003505   \n",
       "\n",
       "   defense_success_rate_pass  defense_success_rate_run  points_scored  \\\n",
       "0                   0.430818                  0.416842            444   \n",
       "1                   0.433600                  0.297561            290   \n",
       "2                   0.434572                  0.445161            317   \n",
       "3                   0.378029                  0.368421            339   \n",
       "4                   0.422018                  0.342105            430   \n",
       "\n",
       "   points_allowed  score_differential  wins  losses  ties  \n",
       "0             338                 106    12       4     0  \n",
       "1             387                 -97     8       8     0  \n",
       "2             335                 -18     8       8     0  \n",
       "3             388                 -49     6      10     0  \n",
       "4             305                 125    11       5     0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_lte_2020.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11baf840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeCategory(y) :\n",
    "    \"\"\"\n",
    "    Encode the target category/class using a\n",
    "    label encoder\n",
    "\n",
    "    Args: \n",
    "        y: target category from data set\n",
    "    \n",
    "    Returns:\n",
    "        y_encoded: encoded version of target category from data set\n",
    "    \"\"\"\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "\n",
    "    return y_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86df5530",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode training data\n",
    "y_lte_2020_encoded = encodeCategory(y_lte_2020)\n",
    "\n",
    "#encode test data\n",
    "y_gt_2020_encoded =  encodeCategory(y_gt_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "83b1cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_test, y_pred) :\n",
    "    \"\"\"\n",
    "    get root mean squared error using test data and predicted results\n",
    "\n",
    "    Args:\n",
    "        y_test: target category from test data\n",
    "        y_pred: predicted target catagory from test data\n",
    "\n",
    "    Returns:\n",
    "        float: root mean squared error (RMSE)\n",
    "    \"\"\"\n",
    "    return np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# create root mean squared error function as scorer\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False, response_method=['predict'])\n",
    "\n",
    "def createEncoderPreprocessor(scaler, feature_columns) :\n",
    "    \"\"\"\n",
    "    use standard scaler to scale all features to unit variance\n",
    "\n",
    "    Args:\n",
    "        scaler: method used to scale data set (i.e. StandardScaler(), OrdinalEncoder)\n",
    "        feature_columns: list of feature names\n",
    "    \n",
    "    Returns:\n",
    "        transformer object containing the StandardScaler as the preprocessor\n",
    "    \"\"\"\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('encoder', scaler, feature_columns)\n",
    "        ])\n",
    "    return preprocessor\n",
    "\n",
    "# default encoder/scaler\n",
    "ENCODER = StandardScaler()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "334a4e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline models\n",
    "models = {\n",
    "    'knn-c': (KNeighborsClassifier()),\n",
    "    'decisiontree-c': (DecisionTreeClassifier(random_state=42)),\n",
    "    'randomforest-c': (RandomForestClassifier(random_state=42)),\n",
    "    'svc': (SVC(random_state=42)),\n",
    "    # 'knn-r': (KNeighborsRegressor()),\n",
    "    # 'decisiontree-r': (DecisionTreeRegressor(random_state=42)),\n",
    "    # 'randomforest-r': (RandomForestRegressor(random_state=42)),\n",
    "    # 'svr': (SVR()),\n",
    "    # 'ElasticNet': (ElasticNet(random_state=42)),\n",
    "    # 'Ridge-c' : (RidgeClassifier(fit_intercept=False, random_state=42)),\n",
    "    # 'Lasso': (Lasso(random_state=42))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3534b307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeModelsForBaselineEval(pipe_models, X_train, y_train, X_test, y_test, scorer_fx) :\n",
    "    \"\"\"\n",
    "    Execute pipeline containing encoded data\n",
    "    and target models with a custom scorer function\n",
    "\n",
    "    Args: \n",
    "        pipe_model: list of models\n",
    "        X_train: DataFrame: contains training features\n",
    "        y_train: ndarray: contains target category training data\n",
    "        X_test: DataFrame: contains test features\n",
    "        y_test: ndarray: contains target category test data\n",
    "        scorer_fx: error function\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: contains results for each model.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for name, (model) in pipe_models.items():\n",
    "        # Create a pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', createEncoderPreprocessor(ENCODER, X_train.columns.tolist())),\n",
    "            (name, model)\n",
    "        ])\n",
    "        feature_cnt = len(X_train.columns.tolist())\n",
    "        \n",
    "        # Perform grid search\n",
    "        grid_search = GridSearchCV(pipeline, param_grid={}, cv=5, n_jobs=-1, scoring=scorer_fx)\n",
    "        \n",
    "        # Fit the model and time it\n",
    "        start_time = time.time()\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        fit_time = (time.time() - start_time) / len(grid_search.cv_results_['mean_fit_time'])\n",
    "        \n",
    "        # Get the best estimator\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        ## print(\"Best params: \\n\", grid_search.best_params_)\n",
    "        # print(\"\\nBest estimator: \\n\", grid_search.best_estimator_)\n",
    "        \n",
    "        # Evaluate on training and test sets\n",
    "        train_score = best_model.score(X_train, y_train)\n",
    "        test_score = best_model.score(X_test, y_test)\n",
    "\n",
    "        # extract best root mean squared error\n",
    "        best_rmse = -grid_search.best_score_\n",
    "        # print(f\"best RMSE: {best_rmse}\")\n",
    "        \n",
    "        # Append the results\n",
    "        results.append([name + '-baseline', feature_cnt, best_params, train_score, test_score, best_rmse, fit_time])\n",
    "\n",
    "    # Create the results DataFrame\n",
    "    results_df = pd.DataFrame(results, columns=['model', 'feature count', 'best params', 'train score', 'test score', 'rmse', 'average fit time'])\n",
    "    results_df.reset_index(inplace=True)\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "627d5c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>rmse</th>\n",
       "      <th>average fit time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn-c-baseline</td>\n",
       "      <td>0.910156</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.354344</td>\n",
       "      <td>0.106525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>decisiontree-c-baseline</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.335189</td>\n",
       "      <td>0.045166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>randomforest-c-baseline</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.277802</td>\n",
       "      <td>0.312306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svc-baseline</td>\n",
       "      <td>0.957031</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.351932</td>\n",
       "      <td>0.039780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  train score  test score      rmse  \\\n",
       "0           knn-c-baseline     0.910156    0.828125  0.354344   \n",
       "1  decisiontree-c-baseline     1.000000    0.906250  0.335189   \n",
       "2  randomforest-c-baseline     1.000000    0.875000  0.277802   \n",
       "3             svc-baseline     0.957031    0.828125  0.351932   \n",
       "\n",
       "   average fit time  \n",
       "0          0.106525  \n",
       "1          0.045166  \n",
       "2          0.312306  \n",
       "3          0.039780  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 1: Feature Selection - get baseline using X training features allstats_X_train\n",
    "\n",
    "# create baseline models for all-stats vs score differential\n",
    "results_df = executeModelsForBaselineEval(models, X_lte_2020, y_lte_2020_encoded, X_gt_2020, y_gt_2020_encoded, rmse_scorer)\n",
    "\n",
    "results_df.to_json('results/allstats_makeplayoffs_baseline_model_results_df.json', orient='records', double_precision=10)\n",
    "\n",
    "# baseline results\n",
    "baseline_df = pd.read_json(r'results/allstats_makeplayoffs_baseline_model_results_df.json')\n",
    "baseline_df[['model', 'train score','test score', 'rmse','average fit time']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fce240b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "93ae7f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCorrelationHeatMap(X, figsize) :\n",
    "    \"\"\"\n",
    "    Calculate the correlation between features\n",
    "    and create a heat map from the results\n",
    "\n",
    "    Args:\n",
    "        X: DataFrame: contains feature data\n",
    "        figsize: tuple containing the size of the diagram\n",
    "    \"\"\"\n",
    "    corr = X.corr()\n",
    "\n",
    "    # Generate the heatmap\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(corr,annot=True, cmap='coolwarm', linewidths=0.5, linecolor='black',\n",
    "                xticklabels=corr.columns, yticklabels=corr.columns)  # Consider turning off annotations for speed\n",
    "    plt.show()\n",
    "\n",
    "def calculatePermutationImportance(model_regressor, X_train, y_train, X_test, y_test, encoder=None) :\n",
    "    \"\"\"\n",
    "    this calculates each feature's permutation-importance on the test data\n",
    "    using a model regressor (i.e. RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "     \n",
    "    NOTE: can be used to compare accuracy and correlation of features with permutation importance\n",
    "    If high accuracy is observed with no features having importance there might be multicollinearity\n",
    "    occuring within feature set.\n",
    "     \n",
    "    Return: Tuple {\n",
    "                   data frame: containing importance score for each column in training/test data, \n",
    "                   float:      accuracy score from baseline prediction using model-regressor\n",
    "                  }\n",
    "\n",
    "    Args:\n",
    "        model_regressor: type of model used for selecting features\n",
    "        X_train: features from training data set\n",
    "        y_train: category from training data set\n",
    "        X_test: features from test data set\n",
    "        y_test: category from test data set\n",
    "        encoder: type of scaler/encoder to encoding the data set\n",
    "    \n",
    "    Returns:\n",
    "        dict: list of features with importance value\n",
    "        float: number of features\n",
    "        float: score\n",
    "        error: RMSE\n",
    "\n",
    "    \"\"\"\n",
    "    # set encoder\n",
    "    if (encoder == None):\n",
    "        encoder = ENCODER # default\n",
    "\n",
    "    pipe_model = Pipeline([('preprocessor', createEncoderPreprocessor(encoder, X_train.columns.tolist())),\n",
    "                           ('regressor', model_regressor)\n",
    "                        ])\n",
    "    \n",
    "    pipe_model.fit(X_train, y_train)\n",
    "    score = pipe_model.score(X_test, y_test)\n",
    "    y_pred = pipe_model.predict(X_test)\n",
    "    error = rmse(y_test, y_pred)\n",
    "\n",
    "    results = permutation_importance(pipe_model, X_test, y_test, n_repeats=10, n_jobs=-1, random_state=42)\n",
    "    results_df = pd.DataFrame(data=results.importances_mean, index=X_train.columns, columns=['Importance']).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    return results_df, len(results_df), score, error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "800f6ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: Feature Evaluation using RandomForestClassifier for [total stats vs making to playoffs]:\n",
      "Accuracy: feature-count: 54, 0.875, RMSE: 0.3535533905932738\n",
      "STEP 1: Feature Evaluation using DecisionTreeClassifier for [total stats vs making to playoffs]:\n",
      "Accuracy: feature-count: 54, 0.90625, RMSE: 0.30618621784789724\n"
     ]
    }
   ],
   "source": [
    "# all stats vs making playoffs\n",
    "step1_perm_imp_selected_features, feature_cnt, score, error = calculatePermutationImportance(RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "                                            X_lte_2020, y_lte_2020_encoded, X_gt_2020, y_gt_2020_encoded\n",
    "                                        )\n",
    "# print(f'STEP 1: Feature Evaluation for [total stats vs points differential]:\\nAccuracy: feature-count: {feature_cnt}, {score}, RMSE: {error}\\n{step1_perm_imp_selected_features}\\n')\n",
    "print(f'STEP 1: Feature Evaluation using RandomForestClassifier for [total stats vs making to playoffs]:\\nAccuracy: feature-count: {feature_cnt}, {score}, RMSE: {error}')\n",
    "\n",
    "step1_perm_imp_selected_features, feature_cnt, score, error = calculatePermutationImportance(DecisionTreeClassifier(random_state=42),\n",
    "                                            X_lte_2020, y_lte_2020_encoded, X_gt_2020, y_gt_2020_encoded\n",
    "                                        )\n",
    "# print(f'STEP 1: Feature Evaluation for [total stats vs points differential]:\\nAccuracy: feature-count: {feature_cnt}, {score}, RMSE: {error}\\n{step1_perm_imp_selected_features}\\n')\n",
    "print(f'STEP 1: Feature Evaluation using DecisionTreeClassifier for [total stats vs making to playoffs]:\\nAccuracy: feature-count: {feature_cnt}, {score}, RMSE: {error}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fad7178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix for the entire data set\n",
    "createCorrelationHeatMap(X=X_lte_2020, figsize=(40, 32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f311950",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculateOptimalPath(X_train, y_train, X_test, y_test) :\n",
    "    \"\"\"\n",
    "    Calculate optimal paths using DecisionTree.cost_complexity_pruning(...)\n",
    "    \n",
    "    Args:\n",
    "        X_train: training data\n",
    "        y_train: target feature/class from training data\n",
    "        X_test: test data\n",
    "        y_test: target feature/class from test data\n",
    "    \n",
    "    Returns:\n",
    "        (Dataframe, Pruning Path):\n",
    "            Dataframe: ['best params', 'ccp-alpha', 'node count', 'depth', 'train accuracy', 'test accuracy', 'rmse']\n",
    "            Pruning Path: pruning path and results from fitted DecisionTreeClassifier model\n",
    "        \n",
    "    \"\"\"\n",
    "    # init\n",
    "    results = {}\n",
    "\n",
    "    dtree = DecisionTreeClassifier(random_state = 42).fit(X_train, y_train)\n",
    "    path = dtree.cost_complexity_pruning_path(X_train, y_train)\n",
    "    # print('CCP Alphas and Impurities:\\n', path)\n",
    "\n",
    "    ccp_alphas = path.ccp_alphas\n",
    "\n",
    "    preprocessor = createEncoderPreprocessor(ENCODER, X_train.columns.tolist())\n",
    "\n",
    "    # calculate node counts, different depths and accuracy based on the provided ccp alpha values\n",
    "    for i in ccp_alphas[:-1]:\n",
    "        # Create a pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            (\"dt-c\", DecisionTreeClassifier(random_state=42, ccp_alpha=i))\n",
    "        ])\n",
    "\n",
    "        model_grid = GridSearchCV(pipeline, param_grid={}, cv=10, n_jobs=-1, scoring=rmse_scorer) # using default criterion - gini\n",
    "        model_grid.fit(X_train, y_train)\n",
    "        best_model = model_grid.best_estimator_\n",
    "        best_params = model_grid.best_params_\n",
    "\n",
    "        # Append the results\n",
    "        results.append([best_params, i, best_model.tree_.node_count, best_model.get_depth(), best_model.score(X_train, y_train), best_model.score(X_test, y_test), -model_grid.best_score_])\n",
    "\n",
    "    # Create the results DataFrame\n",
    "    results_df = pd.DataFrame(results, columns=['best params', 'ccp-alpha', 'node count', 'depth', 'train accuracy', 'test accuracy', 'rmse'])\n",
    "    results_df.reset_index(inplace=True)\n",
    "\n",
    "    # return results and pruning path containing ccp-alphas and impurities\n",
    "    return results_df, path\n",
    "\n",
    "def showImpureNodesVsCcpAlphas(path) :\n",
    "    \"\"\"\n",
    "    Graphically show the relation between impure nodes and the ccp alpha values\n",
    "    Args:\n",
    "        path: DecisionTreeClassifier pruning path\n",
    "    \"\"\"\n",
    "\n",
    "    plt.step(path.ccp_alphas[:-1], path.impurities[:-1], '--o')\n",
    "    plt.title('Impurity vs. Effective Alpha')\n",
    "    plt.xlabel('Effective Alphas')\n",
    "    plt.ylabel('Total Impurity of Leaves')\n",
    "\n",
    "def showCcpAlphasVsOptimalNodes(nodes, ccp_alphas) :\n",
    "    \"\"\"\n",
    "    Graphically show CCP Alphas in relation to the number of optimal nodes\n",
    "    Args:\n",
    "        nodes: list of optimal nodes\n",
    "        ccp_alphas: list of alphas\n",
    "    \"\"\"\n",
    "    plt.step(ccp_alphas[:-1], nodes, '--o')\n",
    "    plt.xlabel('Alpha')\n",
    "    plt.ylabel('Nodes')\n",
    "    plt.title('CCP Alpha vs. Number of Nodes')\n",
    "    plt.grid()\n",
    "\n",
    "def showCcpAlphasVsAccuracy(train_accs, test_accs, ccp_alphas, depths, nodes, rmses) :\n",
    "    \"\"\"\n",
    "    show the RMSE for each ccp alpha including the best accuracy score\n",
    "    \"\"\"\n",
    "    plt.step(ccp_alphas[:-2], train_accs[:-1], '--o', label = 'Train')\n",
    "    plt.step(ccp_alphas[:-2], test_accs[:-1], '--o', label = 'Test')\n",
    "    plt.plot(ccp_alphas[np.argmax(test_accs)], max(test_accs), 'ro', markersize = 12, alpha = 0.4, label = 'Best Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.title('Accuracy vs Alpha')\n",
    "    plt.xlabel('alpha')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    ccp_alpha_best_idx = np.argmax(test_accs)\n",
    "    print(f\"Best score using all features: {max(test_accs)} <-> CCP Alpha: {ccp_alphas[ccp_alpha_best_idx]} - depth: {depths[ccp_alpha_best_idx]} - nodes: {nodes[ccp_alpha_best_idx]}, rmse: {rmses[ccp_alpha_best_idx]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bb2c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def createSelectedFeatureList(X_train, y_train, X_test, y_test, model_name, model_cfg) :\n",
    "    \"\"\"\n",
    "    Creates a list of features derived from a model using the SelectFromModel API in scikit.learn\n",
    "\n",
    "        Args:\n",
    "            X_train : X features from training data set\n",
    "            y_train : target category from training data set\n",
    "            coefseed : list of coeficients\n",
    "            model_name: name of model\n",
    "            model_cfg: tuple containing model and hyper-params\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: containing coeficient for each feature by coefseed\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    model, hyperparams = model_cfg\n",
    "\n",
    "    # Create a pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', createEncoderPreprocessor(ENCODER, X_train.columns.tolist())),\n",
    "        (model_name, model)\n",
    "    ])\n",
    "\n",
    "    model_grid = GridSearchCV(pipeline, param_grid={}, cv=10, n_jobs=-1, scoring=rmse_scorer)\n",
    "    model_grid.fit(X_train, y_train)\n",
    "\n",
    "    selector = SelectFromModel(estimator=model_grid.best_estimator_, prefit=True)\n",
    "    selector.fit(X_train, y_train)\n",
    "    selected_features = selector.get_feature_names_out()\n",
    "\n",
    "    # Get the best estimator\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_params = model_grid.best_params_\n",
    "    ## print(\"Best params: \\n\", model_grid.best_params_)\n",
    "    # print(\"\\nBest estimator: \\n\", model_grid.best_estimator_)\n",
    "    \n",
    "    # Evaluate on training and test sets\n",
    "    train_score = best_model.score(X_train, y_train)\n",
    "    test_score = best_model.score(X_test, y_test)\n",
    "\n",
    "    # extract best root mean squared error\n",
    "    best_rmse = -model_grid.best_score_\n",
    "    # print(f\"best RMSE: {best_rmse}\")\n",
    "    \n",
    "    # Append the results\n",
    "    results.append([model_name, feature_cnt, best_params, train_score, test_score, best_rmse, selected_features])\n",
    "\n",
    "    # Create the results DataFrame\n",
    "    results_df = pd.DataFrame(results, columns=['model', 'feature count', 'best params', 'train score', 'test score', 'rmse', 'features'])\n",
    "    results_df.reset_index(inplace=True)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85fc663",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_select_hypermodels = {\n",
    "    'knn-c': (KNeighborsClassifier(n_jobs=-1), {\n",
    "                                    'knn__n_neighbors': [2, 5, 10],\n",
    "                                    'knn-c__weights': ['uniform', 'distance'],\n",
    "                                    'knn-c__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                                    'knn-c__p': [1, 2]}), #ERROR: 1 = l1, 2 = l2\n",
    "    'dt-c': (DecisionTreeClassifier(random_state=42), {\n",
    "                                                    'dt-c__criterion': ['gini', 'entropy', 'log_loss']\n",
    "                                                }),\n",
    "    'rf-c': (RandomForestClassifier(random_state=42, n_jobs=-1), {\n",
    "                                                    'rf-c__ccp_alpha': [],\n",
    "                                                    'rf-c__n_estimators': [100, 1000],\n",
    "                                                    'rf-c__criterion': ['gini', 'entropy', 'log_loss']\n",
    "                                                }),\n",
    "    'svc': (SVC(random_state=42), {\n",
    "                                'svc__C': [0.1, 1, 10],\n",
    "                                'svc__gamma': [],\n",
    "                                'svc__kernel': ['linear', 'rbf', 'poly', 'linear', 'sigmoid']\n",
    "                            }),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b55e442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Feature Selection: create initial coeficients\n",
    "print(\"STEP 1: Feature selection - generating initial coeficients using DecisionTreeClassifier\")\n",
    "dt_optimal_features_df = createCoefToFeatureList(X_lte_2020, y_lte_2020_encoded, Cs, 'dt-c', feature_select_hypermodels['dt-c'])\n",
    "dt_optimal_features_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e9184bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: Feature selection - generating initial coeficients using RandomForestClassifier\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "when `importance_getter=='auto'`, the underlying estimator GridSearchCV should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[102], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTEP 1: Feature selection - generating initial coeficients using RandomForestClassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m rf_optimal_features_df \u001b[38;5;241m=\u001b[39m createSelectedFeatureList(X_lte_2020, y_lte_2020_encoded, X_gt_2020, y_gt_2020_encoded, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrf-c\u001b[39m\u001b[38;5;124m'\u001b[39m, feature_select_hypermodels[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrf-c\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m rf_optimal_features_df\n",
      "Cell \u001b[1;32mIn[101], line 29\u001b[0m, in \u001b[0;36mcreateSelectedFeatureList\u001b[1;34m(X_train, y_train, X_test, y_test, model_name, model_cfg)\u001b[0m\n\u001b[0;32m     27\u001b[0m selector \u001b[38;5;241m=\u001b[39m SelectFromModel(estimator\u001b[38;5;241m=\u001b[39mmodel_grid, prefit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     28\u001b[0m selector\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m---> 29\u001b[0m selected_features \u001b[38;5;241m=\u001b[39m selector\u001b[38;5;241m.\u001b[39mget_feature_names_out()\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Get the best estimator\u001b[39;00m\n\u001b[0;32m     32\u001b[0m best_model \u001b[38;5;241m=\u001b[39m model_grid\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_base.py:190\u001b[0m, in \u001b[0;36mSelectorMixin.get_feature_names_out\u001b[1;34m(self, input_features)\u001b[0m\n\u001b[0;32m    188\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    189\u001b[0m input_features \u001b[38;5;241m=\u001b[39m _check_feature_names_in(\u001b[38;5;28mself\u001b[39m, input_features)\n\u001b[1;32m--> 190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m input_features[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_support()]\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_base.py:67\u001b[0m, in \u001b[0;36mSelectorMixin.get_support\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_support\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     48\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    Get a mask, or integer index, of the features selected.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m        values are indices into the input feature vector.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_support_mask()\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mask \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indices \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mwhere(mask)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_from_model.py:299\u001b[0m, in \u001b[0;36mSelectFromModel._get_support_mask\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m max_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(max_features, Integral):\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    295\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`max_features` must be an integer. Got `max_features=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    296\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 299\u001b[0m scores \u001b[38;5;241m=\u001b[39m _get_feature_importances(\n\u001b[0;32m    300\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    301\u001b[0m     getter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimportance_getter,\n\u001b[0;32m    302\u001b[0m     transform_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    303\u001b[0m     norm_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_order,\n\u001b[0;32m    304\u001b[0m )\n\u001b[0;32m    305\u001b[0m threshold \u001b[38;5;241m=\u001b[39m _calculate_threshold(estimator, scores, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_base.py:228\u001b[0m, in \u001b[0;36m_get_feature_importances\u001b[1;34m(estimator, getter, transform_func, norm_order)\u001b[0m\n\u001b[0;32m    226\u001b[0m         getter \u001b[38;5;241m=\u001b[39m attrgetter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_importances_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 228\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    229\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen `importance_getter==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`, the underlying \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    231\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`coef_` or `feature_importances_` attribute. Either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass a fitted estimator to feature selector or call fit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbefore calling transform.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    234\u001b[0m         )\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    236\u001b[0m     getter \u001b[38;5;241m=\u001b[39m attrgetter(getter)\n",
      "\u001b[1;31mValueError\u001b[0m: when `importance_getter=='auto'`, the underlying estimator GridSearchCV should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform."
     ]
    }
   ],
   "source": [
    "print(\"STEP 1: Feature selection - generating initial coeficients using RandomForestClassifier\")\n",
    "rf_optimal_features_df = createSelectedFeatureList(X_lte_2020, y_lte_2020_encoded, X_gt_2020, y_gt_2020_encoded, 'rf-c', feature_select_hypermodels['rf-c'])\n",
    "rf_optimal_features_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a96da85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca4248c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
