{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5134681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install Beautiful Soup used to web page scrape cost data.\n",
    "# pip show beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87865cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd\n",
    "import urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f22d2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "http = urllib3.PoolManager()\n",
    "baseUrl = 'https://overthecap.com/positional-spending#y'\n",
    "search_list = ['2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022']\n",
    "\n",
    "for search_yr in search_list :\n",
    "    url = 'https://overthecap.com/positional-spending#y' + search_yr\n",
    "    html = http.request('GET', url).data.decode('utf-8')\n",
    "    soup = BeautifulSoup(html, features='lxml')\n",
    "    #Specify table name which you want to read.\n",
    "    #Example: <table class=\"queryResults\" border=\"0\" cellspacing=\"1\">\n",
    "    table = soup.select_one('table', attrs={'class': 'sortable positional-spending-table'})\n",
    "\n",
    "    # FOR DEBUGGING ###########\n",
    "    # def get_all_tables(soup):\n",
    "    #     return soup.find_all(\"table\")\n",
    "\n",
    "    # tbls = get_all_tables(soup)\n",
    "    # for i, tablen in enumerate(tbls, start=1):\n",
    "    #     print(i)\n",
    "    #     print(tablen)\n",
    "    ###########################\n",
    "\n",
    "    ## get table column headers\n",
    "    def get_table_headers(table):\n",
    "        headers = []\n",
    "        for th in table.find(\"tr\") \\\n",
    "                    .find_all(\"th\"):\n",
    "            headers.append(th.text.strip())\n",
    "        return headers\n",
    "\n",
    "    head = get_table_headers(table)\n",
    "    # print(head) ## FOR DEBUGGING ONLY\n",
    "\n",
    "    def get_table_rows(table):    \n",
    "        rows = []\n",
    "        for tr in table.find_all(\"tr\")[1:]:\n",
    "            cells = []\n",
    "            # grab all td tags in this table row\n",
    "            tds = tr.find_all(\"td\")\n",
    "            if len(tds) == 0:\n",
    "                # if no td tags, search for th tags\n",
    "                # can be found especially in wikipedia tables below the table\n",
    "                ths = tr.find_all(\"th\")\n",
    "                for th in ths:\n",
    "                    cells.append(th.text.strip())\n",
    "            else:\n",
    "                # use regular td tags\n",
    "                for td in tds:\n",
    "                    cells.append(td.text.strip())\n",
    "            rows.append(cells)\n",
    "        return rows\n",
    "\n",
    "    table_rows = get_table_rows(table)\n",
    "    #print(table_rows)  ## FOR DEBUGGING ONLY\n",
    "\n",
    "    ## save results to CSV\n",
    "    def save_as_csv(table_name, headers, rows):\n",
    "        pd.DataFrame(rows, columns=headers).to_csv(f\"{table_name}.csv\")\n",
    "\n",
    "    ## save results\n",
    "    save_as_csv(\"raw-data/nfl_team_spending_\"+ search_yr +\"_table\", head, table_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebde5330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
