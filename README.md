# ucb-mlai-capstone
UC Berkeley ML-AI Capstone project

Problem:

Looking to improve upon the AI tools used as software development aids that are currently available in the industry such as Copilot and ChatGPT.  The areas of improvement would revolve around being able to go from use cases to a more iterative process that minimizes the amount of software written by a software engineer.  The software in question would be the product of what is normally used in a implementing and deploying a software application as well as the work required to unit and regression test said application.

 

Data:

The type of data used to implement this process would be what is generally found in Large Language Models (LLMs) like GPT-4 and LLaMA.

 

Techniques:

I have just started looking at the problem with regards to what other people have done, so with regards to what techniques to use, that is still unclear.  I would think something along the lines of doing some form of Natural Language Processing incombination with techniques used in a Generative AI algorithm.  To start I would be looking at the innter workings of Retrieval Augmented Generation (RAG) and Generative Adversarial Networks (GAN).

Topics to investigate:
- Prompt Engineering
- Variational Autoencoders (VAEs)
- Generative Adversarial Networks (GANs)
- Transformers
- Retrieval Augmented Generation (RAG)
- LLM Architecture, Fine-Tuning and Benchmarking
- Attention Mechanism
- Langchain for Workflow Design
- GenAI Application Development
- Stable Diffusion
- Generative AI Governance

Tools an Technologies to investigate:
- LangChain
- Streamlit
- Gradio
- Chroma
- Hugging Faces
- Dall-E2
- Bard
