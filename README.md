# ucb-mlai-capstone
UC Berkeley ML-AI Capstone project

Problem:

Looking to improve upon the AI tools used as software development aids that are currently available in the industry such as Copilot and ChatGPT.  The areas of improvement would revolve around being able to go from use cases to a more iterative process that minimizes the amount of software written by a software engineer.  The software in question would be the product of what is normally used in a implementing and deploying a software application as well as the work required to unit and regression test said application.

 

Data:

The type of data used to implement this process would be what is generally found in Large Language Models (LLMs) like GPT-4 and LLaMA.

 

Techniques:

I have just started looking at the problem with regards to what other people have done, so with regards to what techniques to use, that is still unclear.  I would think something along the lines of doing some form of Natural Language Processing incombination with techniques used in a Generative AI algorithm.  To start I would be looking at the innter workings of Retrieval Augmented Generation (RAG) and Generative Adversarial Networks (GAN).

Topics to investigate:
- Prompt Engineering
- Variational Autoencoders (VAEs)
- Generative Adversarial Networks (GANs)
- Transformers
- Retrieval Augmented Generation (RAG)
- LLM Architecture, Fine-Tuning and Benchmarking
- Attention Mechanism
- Langchain for Workflow Design
- GenAI Application Development
- Stable Diffusion
- Generative AI Governance.  Key points about generative AI governance:
  - Focus on responsible use: It aims to mitigate potential harms associated with generative AI, such as the creation of misinformation, biased content, or deepfakes.
  - Ethical considerations: Governance frameworks address ethical issues like fairness, accountability, and privacy related to generative AI applications.
  - Data management: Proper data governance practices are crucial to ensure the quality and integrity of the data used to train generative AI models.
  - Transparency and explainability: Governance should promote transparency in how generative AI systems function, allowing users to understand how outputs are generated.
  - Monitoring and oversight: Continuous monitoring of generative AI systems is necessary to detect and address potential issues as they arise. 

Tools an Technologies to investigate:
- LangChain
- Streamlit
- Gradio
- Chroma
- Hugging Faces
- Dall-E2
- Bard
